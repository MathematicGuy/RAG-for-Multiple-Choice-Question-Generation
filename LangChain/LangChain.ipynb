{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ebc5c33",
   "metadata": {},
   "source": [
    "## Runnables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebf8b3f",
   "metadata": {},
   "source": [
    "### RunnableMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3abc7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'mul_two': 4, 'mul_three': 6},\n",
       " {'mul_two': 6, 'mul_three': 9},\n",
       " {'mul_two': 8, 'mul_three': 12}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "def add_one(x: int) -> int:\n",
    "    return x + 1\n",
    "\n",
    "def mul_two(x: int) -> int:\n",
    "    return x * 2\n",
    "\n",
    "def mul_three(x: int) -> int:\n",
    "    return x * 3\n",
    "\n",
    "runnable_1 = RunnableLambda(add_one)\n",
    "runnable_2 = RunnableLambda(mul_two)\n",
    "runnable_3 = RunnableLambda(mul_three)\n",
    "\n",
    "sequence = runnable_1 | {  # this dict is coerced to a RunnableParallel\n",
    "    \"mul_two\": runnable_2,\n",
    "    \"mul_three\": runnable_3,\n",
    "}\n",
    "# Or equivalently:\n",
    "# sequence = runnable_1 | RunnableParallel(\n",
    "#     {\"mul_two\": runnable_2, \"mul_three\": runnable_3}\n",
    "# )\n",
    "# Also equivalently:\n",
    "# sequence = runnable_1 | RunnableParallel(\n",
    "#     mul_two=runnable_2,\n",
    "#     mul_three=runnable_3,\n",
    "# )\n",
    "\n",
    "sequence.invoke(1)\n",
    "await sequence.ainvoke(1)\n",
    "\n",
    "sequence.batch([1, 2, 3])\n",
    "await sequence.abatch([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17bcc79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'key': 'value'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.outputs import Generation\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# Create a JsonOutputParser instance\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# Assume we have a Generation object\n",
    "generation = Generation(text='{\"key\": \"value\" ')\n",
    "\n",
    "# Parse the result\n",
    "result = parser.parse_result([generation])\n",
    "\n",
    "# result now contains the parsed JSON object\n",
    "print(result)  # Output: {'key': 'value'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f0ac223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid json output: {'name': 'Tom Hanks', 'film_names': ['Forrest Gump']}\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from langchain_core.exceptions import OutputParserException\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Actor(BaseModel):\n",
    "    name: str = Field(description=\"name of an actor\")\n",
    "    film_names: List[str] = Field(description=\"list of names of films they starred in\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=Actor)\n",
    "misformatted = \"{'name': 'Tom Hanks', 'film_names': ['Forrest Gump']}\" # Example of malformed output\n",
    "\n",
    "try:\n",
    "    parser.parse(misformatted)\n",
    "except OutputParserException as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abaee116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb8473f5e3b4c699918dc89708c7670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline,\n",
    ")\n",
    "from langchain_huggingface.llms import HuggingFacePipeline\n",
    "\n",
    "\n",
    "def load_llm(model_name):\n",
    "    token_path = Path(\"token.txt\")\n",
    "    if not token_path.exists():\n",
    "        raise FileNotFoundError(\"Missing HuggingFace token.txt\")\n",
    "\n",
    "    with token_path.open(\"r\") as f:\n",
    "        hf_token = f.read().strip()\n",
    "\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_quant_type=\"nf4\"\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=bnb_config,\n",
    "        low_cpu_mem_usage=True,\n",
    "        device_map=\"auto\",\n",
    "        token=hf_token\n",
    "    )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    model_pipeline = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_new_tokens=512,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "\n",
    "    return HuggingFacePipeline(pipeline=model_pipeline)\n",
    "\n",
    "MODEL_NAME= \"google/gemma-2b-it\"\n",
    "# MODEL_NAME = \"lmsys/vicuna-7b-v1.5\"\n",
    "llm = load_llm(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7028ce0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to fix the output: Failed to parse Actor from completion {\"properties\": {\"name\": {\"description\": \"name of an actor\", \"title\": \"Name\", \"type\": \"string\"}, \"film_names\": {\"description\": \"list of names of films they starred in\", \"items\": {\"type\": \"string\"}, \"title\": \"Film Names\", \"type\": \"array\"}}, \"required\": [\"name\", \"film_names\"]}. Got: 2 validation errors for Actor\n",
      "name\n",
      "  Field required [type=missing, input_value={'properties': {'name': {... ['name', 'film_names']}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      "film_names\n",
      "  Field required [type=missing, input_value={'properties': {'name': {... ['name', 'film_names']}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/missing\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n",
      "Troubleshooting details:\n",
      "Ensure the malformed output matches the expected schema for the Actor model.\n",
      "Expected fields: 'name' (string) and 'film_names' (list of strings).\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import OutputFixingParser\n",
    "\n",
    "new_parser = OutputFixingParser.from_llm(parser=parser, llm=llm)\n",
    "misformatted = \"{'name': 'Tom Hanks', 'film_names': ['Forrest Gump']}\"  # Example of malformed output\n",
    "\n",
    "try:\n",
    "    result = new_parser.parse(misformatted)\n",
    "    print(result)\n",
    "except OutputParserException as e:\n",
    "    print(f\"Failed to fix the output: {e}\")\n",
    "    print(\"Troubleshooting details:\")\n",
    "    print(\"Ensure the malformed output matches the expected schema for the Actor model.\")\n",
    "    print(\"Expected fields: 'name' (string) and 'film_names' (list of strings).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ba9dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-multi-choice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
